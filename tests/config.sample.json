{
  "app": {
    "provider": "app",
    "path": {
      "local": "${HOME}/.local/share/pygptprompt",
      "cache": "${HOME}/.cache/pygptprompt",
      "config": "${HOME}/.config/pygptprompt"
    },
    "access": {
      "confirm": false,
      "shell": {
        "allowed_commands": [
          "date",
          "cal",
          "pwd",
          "cat",
          "grep",
          "git",
          "tree",
          "virtualenv",
          "poetry",
          "pytest"
        ],
        "disallowed_commands": ["rm", "sudo", "su"],
        "disallowed_strings": ["-rf /", ":(){ :|:& };:"],
        "disallowed_chars": ["&", ";", "*", ">", ">>", "|"]
      },
      "file": {
        "allowed_paths": ["${PWD}", "${HOME}/.cache/pygptprompt"],
        "disallowed_paths": [".env", "${HOME}/.config/pygptprompt"]
      }
    },
    "style": {
      "italic": "italic",
      "bold": "bold"
    }
  },
  "chroma": {
    "provider": "chroma",
    "device": "cpu",
    "model": {
      "repo_id": "hkunlp/instructor-large",
      "class_id": "InstructorEmbeddingFunction",
      "max_tokens": 256
    }
  },
  "torch": {
    "provider": "torch",
    "device": {
      "triton": false,
      "type": "cpu",
      "options": ["cpu", "cuda", "hip", "mps", "opencl", "vulkan", "lazy"]
    }
  },
  "huggingface": {
    "provider": "huggingface"
  },
  "llama_cpp": {
    "provider": "llama_cpp",
    "model": {
      "repo_id": "TheBloke/Llama-2-7B-Chat-GGML",
      "filename": "llama-2-7b-chat.ggmlv3.q5_1.bin",
      "n_ctx": 4096,
      "n_parts": -1,
      "seed": 1337,
      "f16_kv": true,
      "logits_all": false,
      "vocab_only": false,
      "use_mmap": true,
      "use_mlock": false,
      "embedding": true,
      "n_threads": null,
      "n_batch": 512,
      "n_gpu_layers": 0,
      "low_vram": false,
      "last_n_tokens_size": 64,
      "lora_base": null,
      "lora_path": null,
      "tensor_split": null,
      "rope_freq_base": 10000.0,
      "rope_freq_scale": 1.0,
      "verbose": false
    },
    "chat_completions": {
      "max_tokens": 1024,
      "temperature": 0.8,
      "top_p": 0.95,
      "top_k": 40,
      "stop": [],
      "repeat_penalty": 1.1
    },
    "context": {
      "reserve": 0.2,
      "length": 4096
    },
    "system_prompt": {
      "role": "system",
      "content": "My name is Llama. I am a helpful assistant."
    }
  },
  "openai": {
    "provider": "openai",
    "chat_completions": {
      "model": "gpt-3.5-turbo",
      "temperature": 0.0,
      "max_tokens": 1024,
      "top_p": 0.95,
      "n": 1,
      "stop": [],
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "logit_bias": {}
    },
    "embedding": {
      "model": "text-embedding-ada-002"
    },
    "context": {
      "reserve": 0.2,
      "length": 16384
    },
    "system_prompt": {
      "role": "system",
      "content": "My name is ChatGPT. I am a helpful assistant. I will only use the functions I have been provided with."
    }
  },
  "function": {
    "provider": "function",
    "call": "auto",
    "templates": [
      {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "prompt": "How should I dress for this kind of weather?"
      }
    ],
    "definitions": [
      {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": { "type": "string", "enum": ["metric", "uscs"] }
          },
          "required": ["location"]
        }
      }
    ]
  }
}
