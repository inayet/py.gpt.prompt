"""
pygptprompt/storage/function.py
"""
from logging import Logger
from typing import Optional

from pygptprompt.pattern.logger import get_default_logger
from pygptprompt.pattern.model import (
    ChatModel,
    ChatModelDocuments,
    ChatModelEmbedding,
    EmbeddingFunction,
)


class VectorStoreEmbeddingFunction(EmbeddingFunction):
    def __init__(
        self,
        chat_model: ChatModel,
        logger: Optional[Logger] = None,
    ):
        """
        Initialize the ChatModelEmbeddingFunction.

        Args:
            chat_model (ChatModel): The chat model instance, e.g. OpenAIModel or LlamaCppModel API.
        """
        self._model = chat_model

        if logger:
            self._logger = logger
        else:
            self._logger = get_default_logger(self.__class__.__name__)

        # Test for initialization data
        self._logger.debug("Successfully initialized chat model embedding function.")

    def __call__(
        self,
        texts: ChatModelDocuments,
    ) -> ChatModelEmbedding:
        """
        Generate embeddings using the chat model.

        Args:
            texts (List[str]): The input texts for which embeddings need to be generated.

        Returns:
            ChatModelEmbedding (List[List[float]]): The list of embeddings generated by the chat model.
        """
        self._logger.debug("Generating embeddings")

        for text in texts:
            self._logger.debug(f"{text}")

        # Get embeddings from the chat model API
        return self._model.get_embedding(input=texts)
