@startuml ChatSession
!theme blueprint

class ChatCompletionMessage {
    ' Represents a single completion message from the chat model.
}

class ChatModelResponse extends ChatCompletionMessage {
    ' Extends ChatCompletionMessage to include optional function calls and their arguments.
    ' The role of the message.
    + role: Literal["assistant", "user", "system", "function"]
    ' The content of the message.
    + content: NotRequired[str]
    ' The function being called, if applicable.
    + function_call: NotRequired[str]
    ' The arguments for the function call, if applicable.
    + function_args: NotRequired[str]
    ' The user who originated this message, if applicable.
    + user: NotRequired[str]
}

class JSONTemplate extends Protocol {
    ' A base template class for working with JSON files.
}

class ListTemplate extends JSONTemplate {
    ' A template class for managing a list of dictionaries in JSON files.
    ' JSONMap = Dict[str, Any]
    ' JSONList = List[JSONMap]
    - JSONList _data
    + ListTemplate(file_path: str, initial_data: Optional[JSONList], logger: Optional[Logger] = None)
    ' Return the length of the internal data list.
    # int length
    ' Return a copy of the internal data list or None if empty.
    # Optional[JSONList] data
    ' Append a dictionary to the internal data list.
    + bool append(item: JSONMap)
    ' Insert a dictionary at a specific index.
    + bool insert(index: int, item: JSONMap)
    ' Get a dictionary from a specific index.
    + Optional[JSONMap] get(index: int)
    ' Update a dictionary at a specific index.
    + bool update(index: int, item: JSONMap)
    ' Remove a dictionary at a specific index.
    + bool remove(index: int)
    ' Pop a dictionary from a specific index.
    + Optional[JSONMap] pop(index: int)
    ' Clear the internal data list.
    + bool clear()
}

class ContextWindowManager {
    // Contains the current contextual sequence of chat completions
    - int _max_length
    - ListTemplate _list_template
    + ContextWindowManager(file_path: str, initial_data: Optional[JSONList])
    # int max_length
    # int length
    # List[ChatModelResponse] sequence
    + None append(message: ChatModelResponse)
    + Optional[ChatModelResponse] pop_initial_message()
    + bool insert(index: int, message: ChatModelResponse)
    + bool remove(index: int)
    + None clear()
}

class TranscriptManager {
    // Contains complete and full records of every chat completion
    - ListTemplate _list_template
    + TranscriptManager(file_path: str, initial_data: Optional[JSONList])
    + None append(message: ChatModelResponse)
    + List[ChatModelResponse] sequence
}

class ChatSessionTokenManager {
    - str provider
    - ConfigurationManager config
    - ChatModel model
    + float reserve
    + int offset
    + int max_length
    + int max_tokens
    + int upper_bound
    + int reserved_upper_bound
    + int get_sequence_length(text: str)
    + int get_message_length(message: ChatModelResponse)
    + int get_total_message_length(messages: List[ChatModelResponse])
    + bool is_overflow(new_message: ChatModelResponse, messages: List[ChatModelResponse])
}

abstract class ChatModel {
    // ChatModelVector = Union[List[int], List[float]]
    // ChatModelEncoding = ChatModelVector
    // ChatModelEmbedding = List[ChatModelVector]
    - ConfigurationManager _config
    + ChatModel(config: ConfigurationManager)
    + ChatModelTextCompletion get_completion(prompt: str)
    + ChatModelResponse get_chat_completion(messages: List[ChatModelResponse])
    + ChatModelEmbedding get_embedding(input: Union[str, List[str]])
    + ChatModelEncoding get_encoding(text: str)
}

class ChatModelFactory {
    // Provider is one of: openai, llama, llama_cpp, etc...
    - ConfigurationManager _config
    - Dict[str, Callable] _provider_map
    + ChatModelFactory(config: ConfigurationManager):
    + ChatModel create_model(provider: str)
}

class FunctionFactory {
    - ConfigurationManager _config
    - dict[str, Callable] _functions
    - str _function_name
    - dict[str, Any] _function_args
    - Optional[Callable] _function
    + FunctionFactory(config: ConfigurationManager)
    + dict[str, Any] get_function_args(message: ChatModelResponse)
    + Optional[Callable] get_function(message: ChatModelResponse)
    + None register_function(function_name: str, function: Callable)
    + Optional[ChatModelResponse] execute_function(message: ChatModelResponse)
    + Optional[ChatModelResponse] query_function(model: ChatModel, result: ChatModelResponse, messages: List[ChatModelResponse])
}

class ChatSession {
    - ContextWindowManager context_window
    - TranscriptManager transcript
    - ChatSessionTokenManager token_manager
    - ChatModel model
    + ChatSession(provider: str, config: ConfigurationManager)
    + ChatModelResponse send_message(message: ChatModelResponse)
    + List[ChatModelResponse] get_transcript()
    + clear()
}


ContextWindowManager::_list_template o--> ListTemplate : <<component>>
TranscriptManager::_list_template o--> ListTemplate : <<component>>

ChatSession --> ChatModelFactory : <<creates>>
ChatModelFactory --> ChatModel : <<creates>>

FunctionFactory::_config o--> ConfigurationManager
FunctionFactory --> ChatModelResponse : <<uses>>
ChatModel --> FunctionFactory : <<uses>>

ChatSession --> ChatModelResponse : <<uses>>
ChatSession --> ChatModel : <<uses>>
ChatSession --> ContextWindowManager : <<uses>>
ChatSession --> TranscriptManager : <<uses>>
ChatSession --> ChatSessionTokenManager : <<uses>>

@enduml